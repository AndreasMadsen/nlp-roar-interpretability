{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initial Prototype"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import math\n",
    "\n",
    "from comp550.dataset import SSTDataset\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dataset = SSTDataset(cachedir=\"cache\", num_workers=0)\n",
    "dataset.prepare_data()\n",
    "dataset.setup(\"fit\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def _compute_frequency_not_in_class_and_not_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataset.dataloader('train', shuffle=False):\n",
    "        for observation in dataset.uncollate(batch):\n",
    "            if token_id not in observation['sentence'] and observation['label'] != class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency / total\n",
    "\n",
    "def _compute_frequency_in_class_and_not_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataset.dataloader('train', shuffle=False):\n",
    "        for observation in dataset.uncollate(batch):\n",
    "            if token_id not in observation['sentence'] and observation['label'] == class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency / total\n",
    "\n",
    "def _compute_frequency_not_in_class_and_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataset.dataloader('train', shuffle=False):\n",
    "        for observation in dataset.uncollate(batch):\n",
    "            if token_id in observation['sentence'] and observation['label'] != class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency / total\n",
    "\n",
    "def _compute_frequency_in_class_and_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataset.dataloader('train', shuffle=False):\n",
    "        for observation in dataset.uncollate(batch):\n",
    "            if token_id in observation['sentence'] and observation['label'] == class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency / total"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# For prototyping, assume we are only analyzing class 0 in SST (i.e., negative).\n",
    "class_ = 0\n",
    "\n",
    "for token_id, token in zip(range(10), tqdm(dataset.tokenizer.token_to_ids)): \n",
    "    # Compute probability of all joint random variable configurations.\n",
    "    p_not_in_class_and_not_in_document = _compute_frequency_not_in_class_and_not_in_document(\n",
    "        dataset, token_id, class_=class_\n",
    "    )\n",
    "    # p_not_in_class_and_not_in_document = 774106 / 801948\n",
    "    p_in_class_and_not_in_document = _compute_frequency_in_class_and_not_in_document(\n",
    "        dataset, token_id, class_=class_\n",
    "    )\n",
    "    # p_in_class_and_not_in_document = 141 / 801948\n",
    "    p_not_in_class_and_in_document = _compute_frequency_not_in_class_and_in_document(\n",
    "        dataset, token_id, class_=class_\n",
    "    )\n",
    "    # p_not_in_class_and_in_document = 27652 / 801948\n",
    "    p_in_class_and_in_document = _compute_frequency_in_class_and_in_document(\n",
    "        dataset, token_id, class_=class_\n",
    "    )\n",
    "    # p_in_class_and_in_document = 49 / 801948\n",
    "\n",
    "    # Compute marginal distributions.\n",
    "    p_not_in_document = p_not_in_class_and_not_in_document + p_in_class_and_not_in_document\n",
    "    p_in_document = p_not_in_class_and_in_document + p_in_class_and_in_document\n",
    "    \n",
    "    p_not_in_class = p_not_in_class_and_not_in_document + p_not_in_class_and_in_document\n",
    "    p_in_class = p_in_class_and_not_in_document + p_in_class_and_in_document\n",
    "    \n",
    "    try:\n",
    "        importance = (\n",
    "            p_in_class_and_in_document * math.log2(p_in_class_and_in_document / (p_in_class * p_in_document)) +\n",
    "            p_not_in_class_and_in_document * math.log2(p_not_in_class_and_in_document / (p_not_in_class * p_in_document)) +\n",
    "            p_in_class_and_not_in_document * math.log2(p_in_class_and_not_in_document / (p_in_class * p_not_in_document)) +\n",
    "            p_not_in_class_and_not_in_document * math.log2(p_not_in_class_and_not_in_document / (p_not_in_class * p_not_in_document))\n",
    "        )\n",
    "    except ZeroDivisionError:\n",
    "        importance = float('nan')\n",
    "\n",
    "    print(f\"Token: {token}\")\n",
    "    print(f\"word = 0, class = 0: {p_not_in_class_and_not_in_document}\")\n",
    "    print(f\"word = 0, class = 1: {p_in_class_and_not_in_document}\")\n",
    "    print(f\"word = 1, class = 0: {p_not_in_class_and_in_document}\")\n",
    "    print(f\"word = 1, class = 1: {p_in_class_and_in_document}\")\n",
    "    print(f\"class = 1: {p_in_class}\")\n",
    "    print(f\"class = 0: {p_not_in_class}\")\n",
    "    print(f\"word = 1: {p_in_document}\")\n",
    "    print(f\"word = 0: {p_not_in_document}\")\n",
    "    print(f\"Importance: {importance}\")\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1/13766 [00:01<6:51:48,  1.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: [PAD]\n",
      "word = 0, class = 0: 0.5242438060495516\n",
      "word = 0, class = 1: 0.4757561939504484\n",
      "word = 1, class = 0: 0.0\n",
      "word = 1, class = 1: 0.0\n",
      "class = 1: 0.4757561939504484\n",
      "Importance: nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 2/13766 [00:03<5:53:48,  1.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: [CLS]\n",
      "word = 0, class = 0: 0.0\n",
      "word = 0, class = 1: 0.0\n",
      "word = 1, class = 0: 0.5242438060495516\n",
      "word = 1, class = 1: 0.4757561939504484\n",
      "class = 1: 0.4757561939504484\n",
      "Importance: nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/13766 [00:04<6:19:02,  1.65s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: [EOS]\n",
      "word = 0, class = 0: 0.0\n",
      "word = 0, class = 1: 0.0\n",
      "word = 1, class = 0: 0.5242438060495516\n",
      "word = 1, class = 1: 0.4757561939504484\n",
      "class = 1: 0.4757561939504484\n",
      "Importance: nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 4/13766 [00:06<6:20:44,  1.66s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: [MASK]\n",
      "word = 0, class = 0: 0.5242438060495516\n",
      "word = 0, class = 1: 0.4757561939504484\n",
      "word = 1, class = 0: 0.0\n",
      "word = 1, class = 1: 0.0\n",
      "class = 1: 0.4757561939504484\n",
      "Importance: nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 5/13766 [00:08<6:00:43,  1.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: [UNK]\n",
      "word = 0, class = 0: 0.5242438060495516\n",
      "word = 0, class = 1: 0.4757561939504484\n",
      "word = 1, class = 0: 0.0\n",
      "word = 1, class = 1: 0.0\n",
      "class = 1: 0.4757561939504484\n",
      "Importance: nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 6/13766 [00:09<5:48:11,  1.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: and\n",
      "word = 0, class = 0: 0.25429396564827483\n",
      "word = 0, class = 1: 0.28058975528195773\n",
      "word = 1, class = 0: 0.2699498404012768\n",
      "word = 1, class = 1: 0.19516643866849065\n",
      "class = 1: 0.4757561939504484\n",
      "Importance: 0.007947550128166982\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 7/13766 [00:10<5:40:10,  1.48s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token: a\n",
      "word = 0, class = 0: 0.25429396564827483\n",
      "word = 0, class = 1: 0.24912600699194407\n",
      "word = 1, class = 0: 0.2699498404012768\n",
      "word = 1, class = 1: 0.22663018695850434\n",
      "class = 1: 0.47575619395044844\n",
      "Importance: 0.001071146203936061\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 7/13766 [00:12<6:42:28,  1.76s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "math domain error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a16337f68344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         importance = (\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mp_in_class_and_in_document\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_in_class_and_in_document\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_in_class\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_in_document\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mp_not_in_class_and_in_document\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_not_in_class_and_in_document\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_not_in_class\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_in_document\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mp_in_class_and_not_in_document\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_in_class_and_not_in_document\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_in_class\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_not_in_document\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}