{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8989ffd1",
   "metadata": {},
   "source": [
    "# Initial Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893bfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from comp550.dataset import SSTDataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3606396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SSTDataset(cachedir=\"cache\", num_workers=4)\n",
    "dataset.prepare_data()\n",
    "dataset.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409f6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_frequency_not_in_class_and_not_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        for sentence, label in zip(batch.sentence.tolist(), batch.label.tolist()):\n",
    "            if token_id not in sentence and label != class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "def _compute_frequency_in_class_and_not_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        for sentence, label in zip(batch.sentence.tolist(), batch.label.tolist()):\n",
    "            if token_id not in sentence and label == class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "def _compute_frequency_not_in_class_and_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        for sentence, label in zip(batch.sentence.tolist(), batch.label.tolist()):\n",
    "            if token_id in sentence and label != class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "def _compute_frequency_in_class_and_in_document(dataloader, token_id, class_, k=0):\n",
    "    total = k\n",
    "    frequency = k\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        for sentence, label in zip(batch.sentence.tolist(), batch.label.tolist()):\n",
    "            if token_id in sentence and label == class_:\n",
    "                frequency += 1\n",
    "            total += 1\n",
    "    \n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717d8ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13766 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [PAD]\n",
      "U = 0, C = 0: 138\n",
      "U = 0, C = 1: 90\n",
      "U = 1, C = 0: 3311\n",
      "U = 1, C = 1: 3040\n",
      "Importance: -83441.22408864423\n",
      "Total count =  6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For prototyping, assume we are only analyzing class 0 in SST (i.e., negative).\n",
    "class_ = 0\n",
    "\n",
    "for token_id, token in enumerate(tqdm(dataset.tokenizer.token_to_ids)): \n",
    "    # Compute probability of all joint random variable configurations.\n",
    "    p_not_in_class_and_not_in_document = _compute_frequency_not_in_class_and_not_in_document(\n",
    "        dataset.train_dataloader(shuffle=False), token_id, class_=class_\n",
    "    )\n",
    "    # p_not_in_class_and_not_in_document = 774106 / 801948\n",
    "    p_in_class_and_not_in_document = _compute_frequency_in_class_and_not_in_document(\n",
    "        dataset.train_dataloader(shuffle=False), token_id, class_=class_\n",
    "    )\n",
    "    # p_in_class_and_not_in_document = 141 / 801948\n",
    "    p_not_in_class_and_in_document = _compute_frequency_not_in_class_and_in_document(\n",
    "        dataset.train_dataloader(shuffle=False), token_id, class_=class_\n",
    "    )\n",
    "    # p_not_in_class_and_in_document = 27652 / 801948\n",
    "    p_in_class_and_in_document = _compute_frequency_in_class_and_in_document(\n",
    "        dataset.train_dataloader(shuffle=False), token_id, class_=class_\n",
    "    )\n",
    "    # p_in_class_and_in_document = 49 / 801948\n",
    "    \n",
    "    # Compute marginal distributions.\n",
    "    p_not_in_document = p_not_in_class_and_not_in_document + p_in_class_and_not_in_document\n",
    "    p_in_document = p_not_in_class_and_in_document + p_in_class_and_in_document\n",
    "    \n",
    "    p_not_in_class = p_not_in_class_and_not_in_document + p_not_in_class_and_in_document\n",
    "    p_in_class = p_in_class_and_not_in_document + p_in_class_and_in_document\n",
    "    \n",
    "    importance = (\n",
    "        p_in_class_and_in_document * math.log2(p_in_class_and_in_document / (p_in_class * p_in_document)) +\n",
    "        p_not_in_class_and_in_document * math.log2(p_not_in_class_and_in_document / (p_not_in_class * p_in_document)) +\n",
    "        p_in_class_and_not_in_document * math.log2(p_in_class_and_not_in_document / (p_in_class * p_not_in_document)) +\n",
    "        p_not_in_class_and_not_in_document * math.log2(p_not_in_class_and_not_in_document / (p_not_in_class * p_not_in_document))\n",
    "    )\n",
    "    \n",
    "    print(f\"Token: {token}\")\n",
    "    print(f\"U = 0, C = 0: {p_not_in_class_and_not_in_document}\")\n",
    "    print(f\"U = 0, C = 1: {p_in_class_and_not_in_document}\")\n",
    "    print(f\"U = 1, C = 0: {p_not_in_class_and_in_document}\")\n",
    "    print(f\"U = 1, C = 1: {p_in_class_and_in_document}\")\n",
    "    print(f\"Importance: {importance}\")\n",
    "    print(\n",
    "        \"Total count = \", \n",
    "          p_not_in_class_and_not_in_document + \n",
    "          p_in_class_and_not_in_document + \n",
    "          p_not_in_class_and_in_document + \n",
    "          p_in_class_and_in_document\n",
    "         )\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66710663",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a585d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from comp550.dataset import SSTDataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296a64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "dataset = SSTDataset(cachedir=\"cache\")\n",
    "dataset.prepare_data()\n",
    "dataset.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c8836b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_token_frequencies(dataloader, tokenizer, class_, in_example_frequency=True, k=1):\n",
    "    \"\"\"Computes the frequency of all tokens in a split (e.g., train) for a particular class\n",
    "    using Laplace smoothing.\"\"\"\n",
    "    vocab_token_ids = set(range(len(tokenizer.token_to_ids)))\n",
    "    \n",
    "    # Initalize token counts for add-k smoothing.\n",
    "    frequencies = Counter()\n",
    "    for token_id in vocab_token_ids:\n",
    "        frequencies[token_id] = k\n",
    "    total = k * len(vocab_token_ids)\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        for sentence, label in zip(batch.sentence.tolist(), batch.label.tolist()):\n",
    "            if label != class_:\n",
    "                continue\n",
    "            \n",
    "            if in_example_frequency:\n",
    "                frequencies.update(set(sentence))\n",
    "            else:\n",
    "                frequencies.update(vocab_token_ids - set(sentence))\n",
    "            \n",
    "            total += 1\n",
    "    \n",
    "    return frequencies\n",
    "\n",
    "frequencies = _compute_token_frequencies(\n",
    "    dataloader=dataset.train_dataloader(shuffle=False), \n",
    "    tokenizer=dataset.tokenizer, \n",
    "    class_=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc9b4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each possible RV configuration.\n",
    "configs = [\n",
    "    (class_, in_example_frequency) \n",
    "    for class_ in range(len(dataset.label_names)) \n",
    "    for in_example_frequency in [True, False]\n",
    "]\n",
    "\n",
    "frequencies = {}\n",
    "for config in configs:\n",
    "    class_, in_example_frequency = config\n",
    "    \n",
    "    frequencies[(class_, in_example_frequency)] = _compute_token_frequencies(\n",
    "        dataloader=dataset.train_dataloader(shuffle=False),\n",
    "        tokenizer=dataset.tokenizer,\n",
    "        class_=class_,\n",
    "        in_example_frequency=in_example_frequency\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
